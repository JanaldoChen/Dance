{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from utils.people_snapshot_dataset import People_Snapshot_Dataset\n",
    "from utils.multi_garment_dataset import Multi_Garment_Dataset\n",
    "from utils.iper_dataset import iPER_Dataset\n",
    "from models.networks.smpl import SMPL\n",
    "from models.networks.render import SMPLRenderer\n",
    "from utils.util import load_obj, load_pickle_file, write_pickle_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'data/Multi-Garment_dataset'\n",
    "pose_cam_path = 'assets/pose_cam.pkl'\n",
    "isHres = True\n",
    "image_size = 256\n",
    "batch_size = 16\n",
    "num_frame = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl = SMPL(pkl_path='assets/smpl_model.pkl', isHres=isHres).cuda()\n",
    "if isHres:\n",
    "    faces = smpl.faces_hres\n",
    "else:\n",
    "    faces = smpl.faces\n",
    "smpl_render = SMPLRenderer(faces=faces).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_render.set_bg_color((1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Multi_Garment_Dataset(data_root=data_root, pose_cam_path=pose_cam_path, num_frame=num_frame, isHres=isHres)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    \n",
    "    shape_src = data['shape'].cuda()\n",
    "    v_personal = data['v_personal'].cuda()\n",
    "    uv_image = data['uv_image'].cuda()\n",
    "    f2vts = data['f2vts'].cuda()\n",
    "    \n",
    "    tex = smpl_render.extract_tex(uv_image, smpl_render.points_to_sampler(f2vts))\n",
    "    \n",
    "    print('shape: ', shape.size())\n",
    "    print('v_personal: ', v_personal.size())\n",
    "    print('uv_image: ', uv_image.size())\n",
    "    print('f2vts: ', f2vts.size())\n",
    "    print('tex: ', tex.size())\n",
    "    \n",
    "    if i >= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ref_root = 'data/iPER'\n",
    "train_ID_list = []\n",
    "for line in open(os.path.join(source_data_root, 'train.txt')):\n",
    "    train_ID_list.append(line.split()[0])\n",
    "print(len(train_ID_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ID = train_ID_list[1]\n",
    "print(video_ID)\n",
    "imgs_path = os.path.join(data_ref_root, 'images', video_ID)\n",
    "pose_shape_pkl_path = os.path.join(data_ref_root, 'smpls', video_ID, 'pose_shape.pkl')\n",
    "train_ref_dataset = iPER_Dataset(imgs_path, pose_shape_pkl_path, image_size=image_size)\n",
    "train_ref_loader = DataLoader(train_ref_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_ref_loader):\n",
    "    img_ref = data['image'].cuda()\n",
    "    shape_ref = data['shape'].cuda()\n",
    "    pose_ref = data['pose'].cuda()\n",
    "    cam_ref = data['cam'].cuda()\n",
    "    print('img: ', img_ref.size())\n",
    "    print('shape: ', shape_ref.size())\n",
    "    print('pose: ', pose_ref.size())\n",
    "    print('cam: ', cam_ref.size())\n",
    "    if i >= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts = smpl(shape, pose, v_personal)\n",
    "verts = smpl_render.project_to_image(verts, cam, flip=True, withz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_masked = smpl_render.render(verts, tex)\n",
    "print(img_masked.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_render.set_ambient_light(int_dir=0.3, int_amb=0.7, direction=(1, 0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_smpl = smpl_render.render(verts)\n",
    "print(img_smpl.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_ID = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vis = (img.detach().cpu().numpy()[vis_ID] * 255).astype(np.uint8).transpose(1, 2, 0)\n",
    "plt.imshow(img_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_masked_vis = (img_masked.detach().cpu().numpy()[vis_ID] * 255).astype(np.uint8).transpose(1, 2, 0)\n",
    "plt.imshow(img_masked_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_smpl_vis = (img_smpl.detach().cpu().numpy()[vis_ID] * 255).astype(np.uint8).transpose(1, 2, 0)\n",
    "plt.imshow(img_smpl_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('dance': conda)",
   "language": "python",
   "name": "python361064bitdancecondabdad1817139c47f69e33e658abb30bab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
